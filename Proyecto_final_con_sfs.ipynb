{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto final con sfs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNerl-cTZI7D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4df0aa2-7343-4615-80d3-ace79f00941b"
      },
      "source": [
        "!pip install qgrid\n",
        "import qgrid\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler # Escalamiento estÃ¡ndar\n",
        "from sklearn.model_selection import train_test_split   \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import scipy as sc\n",
        "import math\n",
        "from numpy import random\n",
        "from numpy import matlib\n",
        "from scipy.spatial import distance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qgrid in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from qgrid) (7.6.5)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from qgrid) (1.1.5)\n",
            "Requirement already satisfied: notebook>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from qgrid) (5.3.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (5.1.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (5.1.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->qgrid) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid) (5.3.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (0.7.5)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->qgrid) (4.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->qgrid) (2.6.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.0.0->qgrid) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.0.0->qgrid) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.0.0->qgrid) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.0.0->qgrid) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid) (22.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0->qgrid) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->qgrid) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->qgrid) (2018.9)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.0.0->qgrid) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.0.0->qgrid) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.0.0->qgrid) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.0.0->qgrid) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.0.0->qgrid) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.0.0->qgrid) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.0.0->qgrid) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.0.0->qgrid) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.0.0->qgrid) (4.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.0.0->qgrid) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.0.0->qgrid) (21.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->notebook>=4.0.0->qgrid) (2.4.7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucI5aPK3Z3bp"
      },
      "source": [
        "#Eliminamos las filas nulas\n",
        "DatosConNulls = pd.read_csv(\"water_potability.csv\", names = None, sep = \",\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIe0lyigH0LC",
        "outputId": "1549f557-516c-4e79-acbd-1157ce695068"
      },
      "source": [
        "DatosConNulls.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 491\n",
              "Hardness             0\n",
              "Solids               0\n",
              "Chloramines          0\n",
              "Sulfate            781\n",
              "Conductivity         0\n",
              "Organic_carbon       0\n",
              "Trihalomethanes    162\n",
              "Turbidity            0\n",
              "Potability           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8Oo8fTwH6u5",
        "outputId": "806643d4-8656-4e3e-af44-4e62c83b7803"
      },
      "source": [
        "#completar los valores en null con su media\n",
        "df1=DatosConNulls[DatosConNulls['Potability']==1].copy()\n",
        "df2=DatosConNulls[DatosConNulls['Potability']==0].copy()\n",
        "df1['ph']=df1['ph'].replace(np.nan, df1['ph'].median())\n",
        "df2['ph']=df2['ph'].replace(np.nan, df2['ph'].median())\n",
        "df1['Sulfate']=df1['Sulfate'].replace(np.nan, df1['Sulfate'].median())\n",
        "df2['Sulfate']=df2['Sulfate'].replace(np.nan, df2['Sulfate'].median())\n",
        "df1['Trihalomethanes']=df1['Trihalomethanes'].replace(np.nan, df1['Trihalomethanes'].median())\n",
        "df2['Trihalomethanes']=df2['Trihalomethanes'].replace(np.nan, df2['Trihalomethanes'].median())\n",
        "Datos=pd.concat([df1,df2], axis=0, ignore_index=True)\n",
        "Datos.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ph                 0\n",
              "Hardness           0\n",
              "Solids             0\n",
              "Chloramines        0\n",
              "Sulfate            0\n",
              "Conductivity       0\n",
              "Organic_carbon     0\n",
              "Trihalomethanes    0\n",
              "Turbidity          0\n",
              "Potability         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgnPZGdklQ-B"
      },
      "source": [
        "X = Datos.iloc[:,0:9] #Caracteristicas\n",
        "Nombres = Datos.columns\n",
        "Y = Datos['Potability']#clases\n",
        "#Ya que la diferencia entre las escalas de los datos de X, se harÃ¡ una normalizaciÃ³n de los datos \n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_escalado = scaler.transform(X)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h41D5NQkwX91"
      },
      "source": [
        "def completarTablaRedesNeuronales (i,tablaRedesNeuronales,EV,IC,F1,ICF1,PR):\n",
        "  tablaRedesNeuronales.loc[i,\"Porcentaje de reduccion\"] = str(PR)\n",
        "  tablaRedesNeuronales.loc[i,\"Eficiencia en validacion\"] = str(EV) # reemplazar los valores\n",
        "  tablaRedesNeuronales.loc[i,\"Intervalo de confianza de eficiencia\"] = str(IC)\n",
        "  tablaRedesNeuronales.loc[i,\"f1-score\"] = str(F1)\n",
        "  tablaRedesNeuronales.loc[i,\"Intervalo de confianza de f1-score\"] = str(ICF1)\n",
        "  return(tablaRedesNeuronales)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk1Upv4C22-J"
      },
      "source": [
        "def completarTablaSoporteVectorial (i,tablaSoporteVectorial,EV,IC,PV,F1,ICF1,PR):\n",
        "  tablaSoporteVectorial.loc[i,\"Porcentaje de reduccion\"] = str(PR)\n",
        "  tablaSoporteVectorial.loc[i,\"Eficiencia en validacion\"] = str(EV)\n",
        "  tablaSoporteVectorial.loc[i,\"Intervalo de confianza de eficiencia\"] = str(IC)\n",
        "  tablaSoporteVectorial.loc[i, \"% de Vectores de Soporte\"] = str(PV)\n",
        "  tablaSoporteVectorial.loc[i,\"f1-score\"] = str(F1)\n",
        "  tablaSoporteVectorial.loc[i,\"Intervalo de confianza de f1-score\"] = str(ICF1)\n",
        "  return(tablaSoporteVectorial)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmzGKrDLKEi5"
      },
      "source": [
        "def completarTablaBoostingTree (pos,tablaBoostingTree,EV,IC,F1,ICF1,PR):\n",
        "  tablaBoostingTree.loc[pos,\"Porcentaje de reduccion\"] = str(PR)\n",
        "  tablaBoostingTree.loc[pos,\"Eficiencia en validacion\"] = str(EV) \n",
        "  tablaBoostingTree.loc[pos,\"Intervalo de confianza\"] = str(IC)\n",
        "  tablaBoostingTree.loc[pos,\"f1-score\"] = str(F1)\n",
        "  tablaBoostingTree.loc[pos,\"Intervalo de confianza de f1-score\"] = str(ICF1)\n",
        "  return(tablaBoostingTree)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44HRfc0Ob4cT"
      },
      "source": [
        "def select_features(modelo, n_features, fwd, fltg):\n",
        "    \"\"\"\n",
        "    Feature Selection Function: helper para el uso de la libreria\n",
        "    #Recibe 4 parÃ¡metros: \n",
        "    1. el modelo (clf para nuestro caso), \n",
        "    2. el nÃºmero de caracterÃ­sticas final que se quiere alcanzar\n",
        "    3. Si es forward (True), si es Backward False, \n",
        "    4. Si es es flotante (True), sino False\n",
        "    \"\"\"\n",
        "    sfs = SFS(modelo, \n",
        "           k_features=n_features, \n",
        "           forward=fwd,\n",
        "           floating=fltg,\n",
        "           verbose=0,\n",
        "           scoring='accuracy',\n",
        "           cv=0, n_jobs=-1)\n",
        "    \n",
        "    return sfs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_55nnKY1frn"
      },
      "source": [
        "# 1. Redes neuronales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUpBxaCcmaaf",
        "outputId": "bb816cfc-8d70-497c-ef32-a6f41edc3d60"
      },
      "source": [
        " #Integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integerY = label_encoder.fit_transform(Y)\n",
        "print(integerY)\n",
        "\n",
        "#Binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integerY = integerY.reshape(len(integerY), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integerY)\n",
        "print(onehot_encoded)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 ... 0 0 0]\n",
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOQwWrbuGpT",
        "outputId": "62b2cecb-5de3-48ef-8c16-f3a50a7498a3"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import scipy as sc\n",
        "import math\n",
        "from numpy import random\n",
        "from numpy import matlib\n",
        "\n",
        "\n",
        "tablaRedesNeuronales= pd.DataFrame({\n",
        "    'Ncaracteristicas' : pd.Series([3,5,7,8,9])})\n",
        "Ncaracteristicas=[3,5,7,8,9]\n",
        "Nfwd=[True,True,True,True,True]\n",
        "Nfltg=[False,False,False,False,False]\n",
        "Ncar = np.array([3,5,7,8,9])\n",
        "\n",
        "for i in range (5):\n",
        "\n",
        "  Folds = 4\n",
        "  random.seed(19680801)\n",
        "  EficienciaTrain = np.zeros(Folds)\n",
        "  EficienciaVal = np.zeros(Folds)\n",
        "  f1 = np.zeros(Folds)\n",
        "  skf = StratifiedKFold(n_splits=Folds)\n",
        "  j = 0\n",
        "  PR=(Ncar[i]/9)*100\n",
        "  for train, test in skf.split(X_escalado, integerY):\n",
        "      Xtrain = X_escalado[train,:]\n",
        "      Ytrain = integerY[train]\n",
        "      Xtest = X_escalado[test,:]\n",
        "      Ytest = integerY[test]\n",
        "      Ytest=Ytest.reshape(len(Ytest))\n",
        "      Ytrain=Ytrain.reshape(len(Ytrain))\n",
        "      \n",
        "      vector=(28,28)  \n",
        "\n",
        "      #Haga el llamado a la funciÃ³n para crear y entrenar el modelo usando los datos de entrenamiento\n",
        "      mlp = MLPClassifier(hidden_layer_sizes=vector, activation='identity', max_iter=400,verbose=True)\n",
        "      mlp.out_activation_='softmax'\n",
        "      sf = select_features(mlp,Ncaracteristicas[i], Nfwd[i], Nfltg[i])\n",
        "\n",
        "      sf=sf.fit(Xtrain,Ytrain)\n",
        "      sf_xtrain = sf.transform(Xtrain)\n",
        "      sf_xtest = sf.transform(Xtest)\n",
        "      mlp=mlp.fit(sf_xtrain,Ytrain)\n",
        "\n",
        "      Ytrain_pred = mlp.predict(sf_xtrain)\n",
        "      Yest = mlp.predict(sf_xtest)\n",
        "\n",
        "      \n",
        "      #Evaluamos las predicciones del modelo con los datos de test\n",
        "      EficienciaTrain[j] = metrics.accuracy_score(Ytrain, Ytrain_pred)\n",
        "      EficienciaVal[j] = metrics.accuracy_score(Ytest, Yest)\n",
        "      f1[j]=metrics.f1_score(Ytest, Yest,average='weighted')\n",
        "      j += 1\n",
        "          \n",
        "  print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
        "  print('Eficiencia durante la validaciÃ³n = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
        "  print(\"f1-score \",str(np.mean(f1)),\" +- \",np.std(f1))\n",
        "  tablaRedesNeuronales = completarTablaRedesNeuronales(i,tablaRedesNeuronales,np.mean(EficienciaVal),np.std(EficienciaVal),np.mean(f1),np.std(f1),PR)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.71110596\n",
            "Iteration 2, loss = 0.67041300\n",
            "Iteration 3, loss = 0.66945392\n",
            "Iteration 4, loss = 0.66869008\n",
            "Iteration 5, loss = 0.66866200\n",
            "Iteration 6, loss = 0.66925585\n",
            "Iteration 7, loss = 0.66859751\n",
            "Iteration 8, loss = 0.66793424\n",
            "Iteration 9, loss = 0.66839164\n",
            "Iteration 10, loss = 0.66828481\n",
            "Iteration 11, loss = 0.66811238\n",
            "Iteration 12, loss = 0.66871840\n",
            "Iteration 13, loss = 0.66801126\n",
            "Iteration 14, loss = 0.66846823\n",
            "Iteration 15, loss = 0.66848362\n",
            "Iteration 16, loss = 0.66877855\n",
            "Iteration 17, loss = 0.66813755\n",
            "Iteration 18, loss = 0.66836113\n",
            "Iteration 19, loss = 0.66864351\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.68420153\n",
            "Iteration 2, loss = 0.67094341\n",
            "Iteration 3, loss = 0.66915606\n",
            "Iteration 4, loss = 0.66922676\n",
            "Iteration 5, loss = 0.66883853\n",
            "Iteration 6, loss = 0.66922928\n",
            "Iteration 7, loss = 0.66903907\n",
            "Iteration 8, loss = 0.66939201\n",
            "Iteration 9, loss = 0.66905134\n",
            "Iteration 10, loss = 0.67030338\n",
            "Iteration 11, loss = 0.66956903\n",
            "Iteration 12, loss = 0.66902389\n",
            "Iteration 13, loss = 0.66938560\n",
            "Iteration 14, loss = 0.66875018\n",
            "Iteration 15, loss = 0.66869940\n",
            "Iteration 16, loss = 0.66904989\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.79646530\n",
            "Iteration 2, loss = 0.69195668\n",
            "Iteration 3, loss = 0.67078919\n",
            "Iteration 4, loss = 0.66843680\n",
            "Iteration 5, loss = 0.66862859\n",
            "Iteration 6, loss = 0.66789272\n",
            "Iteration 7, loss = 0.66749273\n",
            "Iteration 8, loss = 0.66749394\n",
            "Iteration 9, loss = 0.66893783\n",
            "Iteration 10, loss = 0.66747656\n",
            "Iteration 11, loss = 0.66761870\n",
            "Iteration 12, loss = 0.66762760\n",
            "Iteration 13, loss = 0.66818247\n",
            "Iteration 14, loss = 0.66819555\n",
            "Iteration 15, loss = 0.66749304\n",
            "Iteration 16, loss = 0.66799466\n",
            "Iteration 17, loss = 0.66846975\n",
            "Iteration 18, loss = 0.66811982\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.69345556\n",
            "Iteration 2, loss = 0.66881165\n",
            "Iteration 3, loss = 0.66874024\n",
            "Iteration 4, loss = 0.66899829\n",
            "Iteration 5, loss = 0.66845331\n",
            "Iteration 6, loss = 0.66896549\n",
            "Iteration 7, loss = 0.66823871\n",
            "Iteration 8, loss = 0.66845590\n",
            "Iteration 9, loss = 0.66812035\n",
            "Iteration 10, loss = 0.66821277\n",
            "Iteration 11, loss = 0.66890381\n",
            "Iteration 12, loss = 0.66833298\n",
            "Iteration 13, loss = 0.66821717\n",
            "Iteration 14, loss = 0.66875130\n",
            "Iteration 15, loss = 0.66830316\n",
            "Iteration 16, loss = 0.66850322\n",
            "Iteration 17, loss = 0.66931788\n",
            "Iteration 18, loss = 0.66837268\n",
            "Iteration 19, loss = 0.66823184\n",
            "Iteration 20, loss = 0.66970902\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Eficiencia durante el entrenamiento = 0.6099918599918599+-0.000601961719892124\n",
            "Eficiencia durante la validaciÃ³n = 0.6098901098901099+-0.0006105006105006638\n",
            "f1-score  0.4621012175471858  +-  0.0007498897315181274\n",
            "Iteration 1, loss = 0.68031169\n",
            "Iteration 2, loss = 0.67020499\n",
            "Iteration 3, loss = 0.66900426\n",
            "Iteration 4, loss = 0.66890895\n",
            "Iteration 5, loss = 0.66910255\n",
            "Iteration 6, loss = 0.66918903\n",
            "Iteration 7, loss = 0.66869679\n",
            "Iteration 8, loss = 0.66846847\n",
            "Iteration 9, loss = 0.66871029\n",
            "Iteration 10, loss = 0.66832702\n",
            "Iteration 11, loss = 0.66900490\n",
            "Iteration 12, loss = 0.66887728\n",
            "Iteration 13, loss = 0.66825835\n",
            "Iteration 14, loss = 0.66905052\n",
            "Iteration 15, loss = 0.66848503\n",
            "Iteration 16, loss = 0.66805745\n",
            "Iteration 17, loss = 0.66825016\n",
            "Iteration 18, loss = 0.66862992\n",
            "Iteration 19, loss = 0.66823730\n",
            "Iteration 20, loss = 0.66891584\n",
            "Iteration 21, loss = 0.66839631\n",
            "Iteration 22, loss = 0.66834795\n",
            "Iteration 23, loss = 0.66846170\n",
            "Iteration 24, loss = 0.66836816\n",
            "Iteration 25, loss = 0.66863009\n",
            "Iteration 26, loss = 0.66879898\n",
            "Iteration 27, loss = 0.66841114\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.71025684\n",
            "Iteration 2, loss = 0.67191474\n",
            "Iteration 3, loss = 0.66830845\n",
            "Iteration 4, loss = 0.66868775\n",
            "Iteration 5, loss = 0.66798928\n",
            "Iteration 6, loss = 0.66811666\n",
            "Iteration 7, loss = 0.66817846\n",
            "Iteration 8, loss = 0.66880931\n",
            "Iteration 9, loss = 0.66868785\n",
            "Iteration 10, loss = 0.66799647\n",
            "Iteration 11, loss = 0.66875255\n",
            "Iteration 12, loss = 0.66878118\n",
            "Iteration 13, loss = 0.66846772\n",
            "Iteration 14, loss = 0.66834120\n",
            "Iteration 15, loss = 0.66821948\n",
            "Iteration 16, loss = 0.66757655\n",
            "Iteration 17, loss = 0.66821167\n",
            "Iteration 18, loss = 0.66884426\n",
            "Iteration 19, loss = 0.66844532\n",
            "Iteration 20, loss = 0.66858301\n",
            "Iteration 21, loss = 0.66807357\n",
            "Iteration 22, loss = 0.66957484\n",
            "Iteration 23, loss = 0.66925280\n",
            "Iteration 24, loss = 0.66858208\n",
            "Iteration 25, loss = 0.66780207\n",
            "Iteration 26, loss = 0.66806284\n",
            "Iteration 27, loss = 0.66805788\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.74512449\n",
            "Iteration 2, loss = 0.67423467\n",
            "Iteration 3, loss = 0.66942635\n",
            "Iteration 4, loss = 0.66905326\n",
            "Iteration 5, loss = 0.66795819\n",
            "Iteration 6, loss = 0.66783894\n",
            "Iteration 7, loss = 0.66844031\n",
            "Iteration 8, loss = 0.66818348\n",
            "Iteration 9, loss = 0.66780929\n",
            "Iteration 10, loss = 0.66776243\n",
            "Iteration 11, loss = 0.66851525\n",
            "Iteration 12, loss = 0.66919966\n",
            "Iteration 13, loss = 0.66835340\n",
            "Iteration 14, loss = 0.66840075\n",
            "Iteration 15, loss = 0.66769392\n",
            "Iteration 16, loss = 0.66840759\n",
            "Iteration 17, loss = 0.66803164\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.71603817\n",
            "Iteration 2, loss = 0.67497812\n",
            "Iteration 3, loss = 0.66908425\n",
            "Iteration 4, loss = 0.66919019\n",
            "Iteration 5, loss = 0.66876801\n",
            "Iteration 6, loss = 0.66836202\n",
            "Iteration 7, loss = 0.66801244\n",
            "Iteration 8, loss = 0.66797093\n",
            "Iteration 9, loss = 0.66790361\n",
            "Iteration 10, loss = 0.66827737\n",
            "Iteration 11, loss = 0.66830247\n",
            "Iteration 12, loss = 0.66759255\n",
            "Iteration 13, loss = 0.66840881\n",
            "Iteration 14, loss = 0.66804524\n",
            "Iteration 15, loss = 0.66766337\n",
            "Iteration 16, loss = 0.66796661\n",
            "Iteration 17, loss = 0.66809049\n",
            "Iteration 18, loss = 0.66821455\n",
            "Iteration 19, loss = 0.66829701\n",
            "Iteration 20, loss = 0.66820862\n",
            "Iteration 21, loss = 0.66894896\n",
            "Iteration 22, loss = 0.66817934\n",
            "Iteration 23, loss = 0.66791867\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Eficiencia durante el entrenamiento = 0.6111111111111112+-0.0007337304182873477\n",
            "Eficiencia durante la validaciÃ³n = 0.6098901098901099+-0.0006105006105006638\n",
            "f1-score  0.4621012175471858  +-  0.0007498897315181274\n",
            "Iteration 1, loss = 0.68708446\n",
            "Iteration 2, loss = 0.67191381\n",
            "Iteration 3, loss = 0.66849267\n",
            "Iteration 4, loss = 0.66785463\n",
            "Iteration 5, loss = 0.66789486\n",
            "Iteration 6, loss = 0.66778730\n",
            "Iteration 7, loss = 0.66801072\n",
            "Iteration 8, loss = 0.66821441\n",
            "Iteration 9, loss = 0.66840799\n",
            "Iteration 10, loss = 0.66812262\n",
            "Iteration 11, loss = 0.66740333\n",
            "Iteration 12, loss = 0.66794620\n",
            "Iteration 13, loss = 0.66777262\n",
            "Iteration 14, loss = 0.66778608\n",
            "Iteration 15, loss = 0.66836796\n",
            "Iteration 16, loss = 0.66811509\n",
            "Iteration 17, loss = 0.66855859\n",
            "Iteration 18, loss = 0.66789204\n",
            "Iteration 19, loss = 0.66796878\n",
            "Iteration 20, loss = 0.66770613\n",
            "Iteration 21, loss = 0.66832738\n",
            "Iteration 22, loss = 0.66834461\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.70038023\n",
            "Iteration 2, loss = 0.66976046\n",
            "Iteration 3, loss = 0.66864811\n",
            "Iteration 4, loss = 0.66812608\n",
            "Iteration 5, loss = 0.66804097\n",
            "Iteration 6, loss = 0.66814659\n",
            "Iteration 7, loss = 0.66835718\n",
            "Iteration 8, loss = 0.66826111\n",
            "Iteration 9, loss = 0.66813385\n",
            "Iteration 10, loss = 0.66898994\n",
            "Iteration 11, loss = 0.66853952\n",
            "Iteration 12, loss = 0.66816999\n",
            "Iteration 13, loss = 0.66751038\n",
            "Iteration 14, loss = 0.66771011\n",
            "Iteration 15, loss = 0.66840371\n",
            "Iteration 16, loss = 0.66862131\n",
            "Iteration 17, loss = 0.66853320\n",
            "Iteration 18, loss = 0.66863655\n",
            "Iteration 19, loss = 0.66817648\n",
            "Iteration 20, loss = 0.66792172\n",
            "Iteration 21, loss = 0.66881645\n",
            "Iteration 22, loss = 0.66734405\n",
            "Iteration 23, loss = 0.66914907\n",
            "Iteration 24, loss = 0.66765396\n",
            "Iteration 25, loss = 0.66874907\n",
            "Iteration 26, loss = 0.66891921\n",
            "Iteration 27, loss = 0.66823610\n",
            "Iteration 28, loss = 0.66917934\n",
            "Iteration 29, loss = 0.66852354\n",
            "Iteration 30, loss = 0.66804434\n",
            "Iteration 31, loss = 0.66786084\n",
            "Iteration 32, loss = 0.66788066\n",
            "Iteration 33, loss = 0.66815800\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.80822449\n",
            "Iteration 2, loss = 0.68577320\n",
            "Iteration 3, loss = 0.66841298\n",
            "Iteration 4, loss = 0.66771926\n",
            "Iteration 5, loss = 0.66698914\n",
            "Iteration 6, loss = 0.66612895\n",
            "Iteration 7, loss = 0.66684927\n",
            "Iteration 8, loss = 0.66640062\n",
            "Iteration 9, loss = 0.66721289\n",
            "Iteration 10, loss = 0.66696488\n",
            "Iteration 11, loss = 0.66666791\n",
            "Iteration 12, loss = 0.66659455\n",
            "Iteration 13, loss = 0.66646800\n",
            "Iteration 14, loss = 0.66602085\n",
            "Iteration 15, loss = 0.66673689\n",
            "Iteration 16, loss = 0.66718006\n",
            "Iteration 17, loss = 0.66681545\n",
            "Iteration 18, loss = 0.66711060\n",
            "Iteration 19, loss = 0.66635849\n",
            "Iteration 20, loss = 0.66676579\n",
            "Iteration 21, loss = 0.66636721\n",
            "Iteration 22, loss = 0.66662046\n",
            "Iteration 23, loss = 0.66652272\n",
            "Iteration 24, loss = 0.66651232\n",
            "Iteration 25, loss = 0.66679288\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.69777206\n",
            "Iteration 2, loss = 0.67239612\n",
            "Iteration 3, loss = 0.66900255\n",
            "Iteration 4, loss = 0.66761135\n",
            "Iteration 5, loss = 0.66789980\n",
            "Iteration 6, loss = 0.66842294\n",
            "Iteration 7, loss = 0.66779015\n",
            "Iteration 8, loss = 0.66843192\n",
            "Iteration 9, loss = 0.66842133\n",
            "Iteration 10, loss = 0.66905830\n",
            "Iteration 11, loss = 0.66839529\n",
            "Iteration 12, loss = 0.66888199\n",
            "Iteration 13, loss = 0.66802180\n",
            "Iteration 14, loss = 0.66779348\n",
            "Iteration 15, loss = 0.66836488\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Eficiencia durante el entrenamiento = 0.6132478632478633+-0.0023090772726720183\n",
            "Eficiencia durante la validaciÃ³n = 0.6114163614163615+-0.002498581432195536\n",
            "f1-score  0.4676706812144208  +-  0.007680354714662361\n",
            "Iteration 1, loss = 0.70087905\n",
            "Iteration 2, loss = 0.67289093\n",
            "Iteration 3, loss = 0.66877631\n",
            "Iteration 4, loss = 0.66855713\n",
            "Iteration 5, loss = 0.66883484\n",
            "Iteration 6, loss = 0.66944673\n",
            "Iteration 7, loss = 0.66828214\n",
            "Iteration 8, loss = 0.66811473\n",
            "Iteration 9, loss = 0.66822089\n",
            "Iteration 10, loss = 0.66891114\n",
            "Iteration 11, loss = 0.66822360\n",
            "Iteration 12, loss = 0.66838459\n",
            "Iteration 13, loss = 0.66828872\n",
            "Iteration 14, loss = 0.66889120\n",
            "Iteration 15, loss = 0.66891490\n",
            "Iteration 16, loss = 0.66827692\n",
            "Iteration 17, loss = 0.66809320\n",
            "Iteration 18, loss = 0.66835054\n",
            "Iteration 19, loss = 0.66821883\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.74852740\n",
            "Iteration 2, loss = 0.68160669\n",
            "Iteration 3, loss = 0.66891189\n",
            "Iteration 4, loss = 0.66873930\n",
            "Iteration 5, loss = 0.66943948\n",
            "Iteration 6, loss = 0.66852713\n",
            "Iteration 7, loss = 0.66791513\n",
            "Iteration 8, loss = 0.66779914\n",
            "Iteration 9, loss = 0.66835169\n",
            "Iteration 10, loss = 0.66887563\n",
            "Iteration 11, loss = 0.66805933\n",
            "Iteration 12, loss = 0.66813710\n",
            "Iteration 13, loss = 0.66773828\n",
            "Iteration 14, loss = 0.66827406\n",
            "Iteration 15, loss = 0.66829810\n",
            "Iteration 16, loss = 0.66869252\n",
            "Iteration 17, loss = 0.66797569\n",
            "Iteration 18, loss = 0.66762054\n",
            "Iteration 19, loss = 0.66828510\n",
            "Iteration 20, loss = 0.66831104\n",
            "Iteration 21, loss = 0.66882194\n",
            "Iteration 22, loss = 0.66779722\n",
            "Iteration 23, loss = 0.66817349\n",
            "Iteration 24, loss = 0.66803867\n",
            "Iteration 25, loss = 0.66812032\n",
            "Iteration 26, loss = 0.66870073\n",
            "Iteration 27, loss = 0.66915858\n",
            "Iteration 28, loss = 0.66895369\n",
            "Iteration 29, loss = 0.66806148\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.75583960\n",
            "Iteration 2, loss = 0.68025502\n",
            "Iteration 3, loss = 0.66946791\n",
            "Iteration 4, loss = 0.66698930\n",
            "Iteration 5, loss = 0.66605920\n",
            "Iteration 6, loss = 0.66714276\n",
            "Iteration 7, loss = 0.66681988\n",
            "Iteration 8, loss = 0.66668441\n",
            "Iteration 9, loss = 0.66633813\n",
            "Iteration 10, loss = 0.66638827\n",
            "Iteration 11, loss = 0.66666616\n",
            "Iteration 12, loss = 0.66669499\n",
            "Iteration 13, loss = 0.66626546\n",
            "Iteration 14, loss = 0.66805229\n",
            "Iteration 15, loss = 0.66686564\n",
            "Iteration 16, loss = 0.66639704\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.83770077\n",
            "Iteration 2, loss = 0.71178942\n",
            "Iteration 3, loss = 0.67310422\n",
            "Iteration 4, loss = 0.66810259\n",
            "Iteration 5, loss = 0.66831515\n",
            "Iteration 6, loss = 0.66755623\n",
            "Iteration 7, loss = 0.66767924\n",
            "Iteration 8, loss = 0.66834597\n",
            "Iteration 9, loss = 0.66766307\n",
            "Iteration 10, loss = 0.66768637\n",
            "Iteration 11, loss = 0.66751982\n",
            "Iteration 12, loss = 0.66762572\n",
            "Iteration 13, loss = 0.66797579\n",
            "Iteration 14, loss = 0.66753736\n",
            "Iteration 15, loss = 0.66757872\n",
            "Iteration 16, loss = 0.66802183\n",
            "Iteration 17, loss = 0.66833623\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Eficiencia durante el entrenamiento = 0.6125356125356125+-0.00431689121603512\n",
            "Eficiencia durante la validaciÃ³n = 0.6105006105006104+-0.002114836150877791\n",
            "f1-score  0.46564491487013304  +-  0.005778225098358869\n",
            "Iteration 1, loss = 0.68408800\n",
            "Iteration 2, loss = 0.66901519\n",
            "Iteration 3, loss = 0.66851816\n",
            "Iteration 4, loss = 0.66866979\n",
            "Iteration 5, loss = 0.66820773\n",
            "Iteration 6, loss = 0.66849806\n",
            "Iteration 7, loss = 0.66853011\n",
            "Iteration 8, loss = 0.66801664\n",
            "Iteration 9, loss = 0.66795621\n",
            "Iteration 10, loss = 0.66848888\n",
            "Iteration 11, loss = 0.66750427\n",
            "Iteration 12, loss = 0.66781070\n",
            "Iteration 13, loss = 0.66916282\n",
            "Iteration 14, loss = 0.66807832\n",
            "Iteration 15, loss = 0.66850802\n",
            "Iteration 16, loss = 0.66783229\n",
            "Iteration 17, loss = 0.66820707\n",
            "Iteration 18, loss = 0.66862605\n",
            "Iteration 19, loss = 0.66788869\n",
            "Iteration 20, loss = 0.66794123\n",
            "Iteration 21, loss = 0.66864234\n",
            "Iteration 22, loss = 0.66806859\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.68853433\n",
            "Iteration 2, loss = 0.67026219\n",
            "Iteration 3, loss = 0.66971602\n",
            "Iteration 4, loss = 0.66817725\n",
            "Iteration 5, loss = 0.66854349\n",
            "Iteration 6, loss = 0.66818150\n",
            "Iteration 7, loss = 0.66849195\n",
            "Iteration 8, loss = 0.67003243\n",
            "Iteration 9, loss = 0.66991904\n",
            "Iteration 10, loss = 0.66797086\n",
            "Iteration 11, loss = 0.66840179\n",
            "Iteration 12, loss = 0.66773396\n",
            "Iteration 13, loss = 0.66941917\n",
            "Iteration 14, loss = 0.66827249\n",
            "Iteration 15, loss = 0.66805508\n",
            "Iteration 16, loss = 0.66802730\n",
            "Iteration 17, loss = 0.66818683\n",
            "Iteration 18, loss = 0.66931154\n",
            "Iteration 19, loss = 0.66819341\n",
            "Iteration 20, loss = 0.66880499\n",
            "Iteration 21, loss = 0.66904479\n",
            "Iteration 22, loss = 0.66852529\n",
            "Iteration 23, loss = 0.66875067\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.86024757\n",
            "Iteration 2, loss = 0.72020901\n",
            "Iteration 3, loss = 0.67250783\n",
            "Iteration 4, loss = 0.66745786\n",
            "Iteration 5, loss = 0.66704995\n",
            "Iteration 6, loss = 0.66728975\n",
            "Iteration 7, loss = 0.66662650\n",
            "Iteration 8, loss = 0.66632471\n",
            "Iteration 9, loss = 0.66648380\n",
            "Iteration 10, loss = 0.66625568\n",
            "Iteration 11, loss = 0.66656034\n",
            "Iteration 12, loss = 0.66637512\n",
            "Iteration 13, loss = 0.66624362\n",
            "Iteration 14, loss = 0.66655801\n",
            "Iteration 15, loss = 0.66629692\n",
            "Iteration 16, loss = 0.66640849\n",
            "Iteration 17, loss = 0.66678920\n",
            "Iteration 18, loss = 0.66644616\n",
            "Iteration 19, loss = 0.66698529\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.79958831\n",
            "Iteration 2, loss = 0.69321304\n",
            "Iteration 3, loss = 0.67289220\n",
            "Iteration 4, loss = 0.66968434\n",
            "Iteration 5, loss = 0.66764237\n",
            "Iteration 6, loss = 0.66744571\n",
            "Iteration 7, loss = 0.66779491\n",
            "Iteration 8, loss = 0.66785430\n",
            "Iteration 9, loss = 0.66728597\n",
            "Iteration 10, loss = 0.66826178\n",
            "Iteration 11, loss = 0.66750218\n",
            "Iteration 12, loss = 0.66771495\n",
            "Iteration 13, loss = 0.66798387\n",
            "Iteration 14, loss = 0.66843815\n",
            "Iteration 15, loss = 0.66876634\n",
            "Iteration 16, loss = 0.66766654\n",
            "Iteration 17, loss = 0.66793656\n",
            "Iteration 18, loss = 0.66756335\n",
            "Iteration 19, loss = 0.66727931\n",
            "Iteration 20, loss = 0.66774447\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Eficiencia durante el entrenamiento = 0.6125356125356125+-0.0033438495574185847\n",
            "Eficiencia durante la validaciÃ³n = 0.6120268620268621+-0.0027809626309964735\n",
            "f1-score  0.46800597327908106  +-  0.006723795777252328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tfsMaMvK0XAZ",
        "outputId": "a8116129-e159-4369-b31b-21119cbff753"
      },
      "source": [
        "tablaRedesNeuronales"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ncaracteristicas</th>\n",
              "      <th>Porcentaje de reduccion</th>\n",
              "      <th>Eficiencia en validacion</th>\n",
              "      <th>Intervalo de confianza de eficiencia</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>Intervalo de confianza de f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>55.55555555555556</td>\n",
              "      <td>0.6098901098901099</td>\n",
              "      <td>0.0006105006105006638</td>\n",
              "      <td>0.4621012175471858</td>\n",
              "      <td>0.0007498897315181274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>66.66666666666666</td>\n",
              "      <td>0.6098901098901099</td>\n",
              "      <td>0.0006105006105006638</td>\n",
              "      <td>0.4621012175471858</td>\n",
              "      <td>0.0007498897315181274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>77.77777777777779</td>\n",
              "      <td>0.6114163614163615</td>\n",
              "      <td>0.002498581432195536</td>\n",
              "      <td>0.4676706812144208</td>\n",
              "      <td>0.007680354714662361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>88.88888888888889</td>\n",
              "      <td>0.6105006105006104</td>\n",
              "      <td>0.002114836150877791</td>\n",
              "      <td>0.46564491487013304</td>\n",
              "      <td>0.005778225098358869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.6120268620268621</td>\n",
              "      <td>0.0027809626309964735</td>\n",
              "      <td>0.46800597327908106</td>\n",
              "      <td>0.006723795777252328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ncaracteristicas  ... Intervalo de confianza de f1-score\n",
              "0                 3  ...              0.0007498897315181274\n",
              "1                 5  ...              0.0007498897315181274\n",
              "2                 7  ...               0.007680354714662361\n",
              "3                 8  ...               0.005778225098358869\n",
              "4                 9  ...               0.006723795777252328\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuTEtxRY1MLB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbto04E812Nd"
      },
      "source": [
        "# 2. MÃ¡quinas de soporte vectorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl6LYeIW3f7E"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "#Se modifica cada etiqueta para que corresponda a un numero\n",
        "\n",
        "dataSet=[]\n",
        "label = np.unique(Y)\n",
        "encoder=preprocessing.LabelEncoder()\n",
        "encoder.fit(label)\n",
        "data=encoder.transform(Y)\n",
        "dataSet.append(data)\n",
        "dataFrameY=pd.DataFrame(dataSet).values\n",
        "dataFrameY=dataFrameY.T\n",
        "dataFrameY = dataFrameY.astype(np.float)\n",
        "dataFrameY=dataFrameY.ravel() "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv9_N-Aq19vw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b1HBftx1-rY",
        "outputId": "8539efd8-4545-487f-a198-6db5bdf78828"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import pandas as pd\n",
        "import qgrid\n",
        "\n",
        "tablaSoporteVectorial = pd.DataFrame({\n",
        "    'Ncaracteristicas' : pd.Series([3,5,7,8,9])})\n",
        "Ncaracteristicas=[3,5,7,8,9]\n",
        "Nfwd=[True,True,True,True,True]\n",
        "Nfltg=[False,False,False,False,False]\n",
        "Ncar = np.array([3,5,7,8,9])\n",
        "for i in range (5):\n",
        "\n",
        "  #Validamos el modelo\n",
        "  Folds = 4\n",
        "  random.seed(24524)\n",
        "  EficienciaTrain = np.zeros(Folds)\n",
        "  EficienciaVal = np.zeros(Folds)\n",
        "  skf = StratifiedKFold(n_splits=Folds)\n",
        "  f1 = np.zeros(Folds)\n",
        "  j = 0\n",
        "  porcentaje = np.zeros(4)\n",
        "  PR=(Ncar[i]/9)*100\n",
        "\n",
        "  for train, test in skf.split(X_escalado, dataFrameY):\n",
        "      Xtrain = X_escalado[train,:]\n",
        "      Ytrain = dataFrameY[train]\n",
        "      Xtest = X_escalado[test,:]\n",
        "      Ytest = dataFrameY[test]\n",
        "      \n",
        "      #Normalizamos los datos\n",
        "      scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
        "      Xtrain = scaler.transform(Xtrain)\n",
        "      Xtest = scaler.transform(Xtest)\n",
        "      modelo = SVC(kernel= 'rbf', C=10, gamma=0.1,decision_function_shape='ovr') #Si es rbf\n",
        "      \n",
        "      sf = select_features(modelo,Ncaracteristicas[i], Nfwd[i], Nfltg[i])\n",
        "      sf = sf.fit(Xtrain,Ytrain)\n",
        "      sf_xtrain = sf.transform(Xtrain)\n",
        "      sf_xtest = sf.transform(Xtest)\n",
        "      modelo = modelo.fit(sf_xtrain,Ytrain)\n",
        "      #ValidaciÃ³n\n",
        "      Ytrain_pred = modelo.predict(sf_xtrain)\n",
        "      Yest = modelo.predict(sf_xtest)\n",
        "\n",
        "      \n",
        "      #Evaluamos las predicciones del modelo con los datos de test\n",
        "      EficienciaTrain[j] = metrics.accuracy_score(Ytrain, Ytrain_pred)\n",
        "      EficienciaVal[j] = metrics.accuracy_score(Ytest, Yest)\n",
        "      f1[j]=metrics.f1_score(Ytest, Yest,average='weighted')\n",
        "      porcentaje[j] =  len(modelo.support_vectors_) / len(Xtrain)\n",
        "      \n",
        "      j += 1\n",
        "          \n",
        "  print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
        "  print('Eficiencia durante la validaciÃ³n = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
        "  print(\"f1-score \",str(np.mean(f1)),\" +- \",np.std(f1))\n",
        "  tablaSoporteVectorial=completarTablaSoporteVectorial(i,tablaSoporteVectorial,np.mean(EficienciaVal),np.std(EficienciaVal),np.mean(porcentaje),np.mean(f1),np.std(f1),PR)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eficiencia durante el entrenamiento = 0.6799959299959301+-0.01445675242517047\n",
            "Eficiencia durante la validaciÃ³n = 0.6355311355311355+-0.040130838655787066\n",
            "f1-score  0.5840968295610975  +-  0.03667019049325399\n",
            "Eficiencia durante el entrenamiento = 0.7287342287342288+-0.012013408337928709\n",
            "Eficiencia durante la validaciÃ³n = 0.63003663003663+-0.04595411298304962\n",
            "f1-score  0.5943333498899948  +-  0.04255257989408563\n",
            "Eficiencia durante el entrenamiento = 0.7705535205535206+-0.010975341593938004\n",
            "Eficiencia durante la validaciÃ³n = 0.6190476190476191+-0.04319480574190165\n",
            "f1-score  0.5911278521481732  +-  0.04105939710635362\n",
            "Eficiencia durante el entrenamiento = 0.7967032967032968+-0.007379513375852147\n",
            "Eficiencia durante la validaciÃ³n = 0.6169108669108669+-0.03950250321285296\n",
            "f1-score  0.5906230303587088  +-  0.04061641817486643\n",
            "Eficiencia durante el entrenamiento = 0.8263125763125763+-0.008172376628797304\n",
            "Eficiencia durante la validaciÃ³n = 0.605006105006105+-0.036898689221639976\n",
            "f1-score  0.5859246133455577  +-  0.035034982603876705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2oHn6qJBqU0v",
        "outputId": "5992650a-c827-4b30-da36-caff391af94d"
      },
      "source": [
        "tablaSoporteVectorial"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ncaracteristicas</th>\n",
              "      <th>Porcentaje de reduccion</th>\n",
              "      <th>Eficiencia en validacion</th>\n",
              "      <th>Intervalo de confianza de eficiencia</th>\n",
              "      <th>% de Vectores de Soporte</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>Intervalo de confianza de f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>55.55555555555556</td>\n",
              "      <td>0.6355311355311355</td>\n",
              "      <td>0.040130838655787066</td>\n",
              "      <td>0.7026862026862026</td>\n",
              "      <td>0.5840968295610975</td>\n",
              "      <td>0.03667019049325399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>66.66666666666666</td>\n",
              "      <td>0.63003663003663</td>\n",
              "      <td>0.04595411298304962</td>\n",
              "      <td>0.6584249084249084</td>\n",
              "      <td>0.5943333498899948</td>\n",
              "      <td>0.04255257989408563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>77.77777777777779</td>\n",
              "      <td>0.6190476190476191</td>\n",
              "      <td>0.04319480574190165</td>\n",
              "      <td>0.6712454212454213</td>\n",
              "      <td>0.5911278521481732</td>\n",
              "      <td>0.04105939710635362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>88.88888888888889</td>\n",
              "      <td>0.6169108669108669</td>\n",
              "      <td>0.03950250321285296</td>\n",
              "      <td>0.6788766788766789</td>\n",
              "      <td>0.5906230303587088</td>\n",
              "      <td>0.04061641817486643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.605006105006105</td>\n",
              "      <td>0.036898689221639976</td>\n",
              "      <td>0.6903744403744403</td>\n",
              "      <td>0.5859246133455577</td>\n",
              "      <td>0.035034982603876705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ncaracteristicas  ... Intervalo de confianza de f1-score\n",
              "0                 3  ...                0.03667019049325399\n",
              "1                 5  ...                0.04255257989408563\n",
              "2                 7  ...                0.04105939710635362\n",
              "3                 8  ...                0.04061641817486643\n",
              "4                 9  ...               0.035034982603876705\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll4n0dyzmwZG"
      },
      "source": [
        "# 3. Gradient boosting tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qmHHocxsxDr",
        "outputId": "19fd6105-b209-45cd-902a-015324caeea7"
      },
      "source": [
        "tablaBoostingTree =  pd.DataFrame({\n",
        "    'Ncaracteristicas' : pd.Series([3,5,7,8,9])})\n",
        "Ncaracteristicas=[3,5,7,8,9]\n",
        "Nfwd=[True,True,True,True,True]\n",
        "Nfltg=[False,False,False,False,False]\n",
        "Ncar = np.array([3,5,7,8,9])\n",
        "\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  clf = GradientBoostingClassifier(n_estimators=300, learning_rate=0.3\t,max_depth=5, random_state=0)\n",
        "  Folds = 4\n",
        "  EficienciaTrain = np.zeros(Folds)\n",
        "  EficienciaVal = np.zeros(Folds)\n",
        "  f1 = np.zeros(Folds)\n",
        "  skf = StratifiedKFold(n_splits=Folds)\n",
        "  j = 0\n",
        "  PR=(Ncar[i]/9)*100\n",
        "  for train, test in skf.split(X_escalado, integerY):\n",
        "      Xtrain = X_escalado[train,:]\n",
        "      Ytrain = integerY[train]\n",
        "      Xtest = X_escalado[test,:]\n",
        "      Ytest = integerY[test]\n",
        "      Ytest=Ytest.reshape(len(Ytest))\n",
        "      Ytrain=Ytrain.reshape(len(Ytrain))\n",
        "      sf = select_features(clf,Ncaracteristicas[i], Nfwd[i], Nfltg[i])\n",
        "      sf = sf.fit(Xtrain,Ytrain)\n",
        "      sf_xtrain = sf.transform(Xtrain)\n",
        "      sf_xtest = sf.transform(Xtest)\n",
        "      clf.fit(sf_xtrain,Ytrain)\n",
        "      #ValidaciÃ³n\n",
        "      Ytrain_pred = clf.predict(sf_xtrain)\n",
        "      Yest = clf.predict(sf_xtest)\n",
        "\n",
        "      #Evaluamos las predicciones del modelo con los datos de test\n",
        "      EficienciaTrain[j] = metrics.accuracy_score(Ytrain, Ytrain_pred)\n",
        "      EficienciaVal[j] = metrics.accuracy_score(Ytest, Yest)\n",
        "      f1[j]=metrics.f1_score(Ytest, Yest,average='weighted')\n",
        "  print('Eficiencia durante el entrenamiento = ' + str(np.mean(EficienciaTrain)) + '+-' + str(np.std(EficienciaTrain)))\n",
        "  print('Eficiencia durante la validaciÃ³n = ' + str(np.mean(EficienciaVal)) + '+-' + str(np.std(EficienciaVal)))\n",
        "  print(\"f1-score \",str(np.mean(f1)),\" +- \",np.std(f1))\n",
        "  tablaBoostingTree=completarTablaBoostingTree(i,tablaBoostingTree,np.mean(EficienciaVal),np.std(EficienciaVal),np.mean(f1),np.std(f1),PR)\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eficiencia durante el entrenamiento = 0.25+-0.4330127018922193\n",
            "Eficiencia durante la validaciÃ³n = 0.18894993894993894+-0.32727089434833184\n",
            "f1-score  0.1885606038946987  +-  0.32659654625148804\n",
            "Eficiencia durante el entrenamiento = 0.25+-0.4330127018922193\n",
            "Eficiencia durante la validaciÃ³n = 0.19230769230769232+-0.3330866937632457\n",
            "f1-score  0.19141225927645192  +-  0.33153575825836185\n",
            "Eficiencia durante el entrenamiento = 0.25+-0.4330127018922193\n",
            "Eficiencia durante la validaciÃ³n = 0.18833943833943834+-0.32621347627289293\n",
            "f1-score  0.187127575732411  +-  0.32411446866572874\n",
            "Eficiencia durante el entrenamiento = 0.25+-0.4330127018922193\n",
            "Eficiencia durante la validaciÃ³n = 0.18925518925518925+-0.3277996033860512\n",
            "f1-score  0.1877274879491739  +-  0.32515354710524336\n",
            "Eficiencia durante el entrenamiento = 0.25+-0.4330127018922193\n",
            "Eficiencia durante la validaciÃ³n = 0.19444444444444445+-0.3367876570272817\n",
            "f1-score  0.19324473254885624  +-  0.3347096950696782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "JdsqkRzAszQ6",
        "outputId": "8615f5cf-3b1a-4f3c-f3c6-cebeb6da29f4"
      },
      "source": [
        "tablaBoostingTree"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ncaracteristicas</th>\n",
              "      <th>Porcentaje de reduccion</th>\n",
              "      <th>Eficiencia en validacion</th>\n",
              "      <th>Intervalo de confianza</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>Intervalo de confianza de f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>55.55555555555556</td>\n",
              "      <td>0.18894993894993894</td>\n",
              "      <td>0.32727089434833184</td>\n",
              "      <td>0.1885606038946987</td>\n",
              "      <td>0.32659654625148804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>66.66666666666666</td>\n",
              "      <td>0.19230769230769232</td>\n",
              "      <td>0.3330866937632457</td>\n",
              "      <td>0.19141225927645192</td>\n",
              "      <td>0.33153575825836185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>77.77777777777779</td>\n",
              "      <td>0.18833943833943834</td>\n",
              "      <td>0.32621347627289293</td>\n",
              "      <td>0.187127575732411</td>\n",
              "      <td>0.32411446866572874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>88.88888888888889</td>\n",
              "      <td>0.18925518925518925</td>\n",
              "      <td>0.3277996033860512</td>\n",
              "      <td>0.1877274879491739</td>\n",
              "      <td>0.32515354710524336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.19444444444444445</td>\n",
              "      <td>0.3367876570272817</td>\n",
              "      <td>0.19324473254885624</td>\n",
              "      <td>0.3347096950696782</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Ncaracteristicas  ... Intervalo de confianza de f1-score\n",
              "0                 3  ...                0.32659654625148804\n",
              "1                 5  ...                0.33153575825836185\n",
              "2                 7  ...                0.32411446866572874\n",
              "3                 8  ...                0.32515354710524336\n",
              "4                 9  ...                 0.3347096950696782\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}